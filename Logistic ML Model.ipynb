{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c525e",
   "metadata": {},
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf15e4",
   "metadata": {},
   "source": [
    "# Upload and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c598f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a Pandas DataFrame\n",
    "\n",
    "districts = pd.read_csv('District_data.csv')\n",
    "districts = districts.replace('redacted',0)\n",
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebcc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data types.\n",
    "districts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary variable showing whether a district has above 50% proficiency or below.\n",
    "districts['Math_metAbove50'] = np.where(districts['Math_metAbove'] >= 50, True, False)\n",
    "districts['ELA_metAbove50'] = np.where(districts['ELA_metAbove'] >= 50, True, False)\n",
    "districts['Math_metAbove50'] = districts['Math_metAbove50'].astype(int)\n",
    "districts['ELA_metAbove50'] = districts['ELA_metAbove50'].astype(int)\n",
    "districts.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ffff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename average years of teaching column.\n",
    "districts = districts.rename(columns={\"Avg Years Teaching (District)\": \"Avg_years_teaching\"})\n",
    "districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a63ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaaNs with means.\n",
    "districts = districts.fillna(districts.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385c15c",
   "metadata": {},
   "source": [
    "# Predicting ELA Proficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "\n",
    "X = districts[[\"Enrollment\",\"FRL_Perc\",\"Teach_to_stud\",\"Per_pupil_exp\",\"Teacher_salary\",\"Avg_years_teaching\"]]\n",
    "y = districts[\"ELA_metAbove50\"]\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06672a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Sklearn `train_test_split()` function to split the data into training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data. \n",
    "\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60349f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training and testing scores.\n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d05dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions.\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy score.\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b946f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report.\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650584ed",
   "metadata": {},
   "source": [
    "# Predicting Math Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "168be2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1036, 6) (1036,)\n"
     ]
    }
   ],
   "source": [
    "# Assign the data to X and y\n",
    "\n",
    "X = districts[[\"Enrollment\",\"FRL_Perc\",\"Teach_to_stud\",\"Per_pupil_exp\",\"Teacher_salary\",\"Avg_years_teaching\"]]\n",
    "y = districts[\"Math_metAbove50\"]\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e807125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Sklearn `train_test_split()` function to split the data into training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60448ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "390ef83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data. \n",
    "\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0326385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.879021879021879\n",
      "Testing Data Score: 0.8996138996138996\n"
     ]
    }
   ],
   "source": [
    "# Print training and testing scores.\n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aa095fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Create predictions.\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3d6fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8996138996138996\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy score.\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "874a8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194  15]\n",
      " [ 11  39]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c08fdec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       209\n",
      "           1       0.72      0.78      0.75        50\n",
      "\n",
      "    accuracy                           0.90       259\n",
      "   macro avg       0.83      0.85      0.84       259\n",
      "weighted avg       0.90      0.90      0.90       259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report.\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d89ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
